# Optimizing Stock Trading Strategies with Various Algorithms

## Overview

This project explores and compares the effectiveness of several AI algorithms in stock trading, focusing on maximizing financial returns or minimizing losses. Algorithms such as **XGBoost**, **Monte Carlo simulations**, **Q-learning**, and **Deep Reinforcement Learning** will be implemented to develop robust trading strategies across various market conditions, including stocks and cryptocurrencies.

## Team Roles

- XGBoost implementation, dataset preparation, and evaluation.
- Q-learning for value-based trading strategies.
- Deep Reinforcement Learning using policy gradients, focusing on fully connected layers and CNNs.
- **Shared Tasks**: Feature engineering, data preprocessing, and evaluation.

## Project Description

We aim to optimize decision-making in stock trading using AI techniques like reinforcement learning. By applying various algorithms, we will analyze their strengths and weaknesses in trading decisions across diverse market conditions (e.g., Bitcoin, Apple). Our evaluation will focus on metrics such as total profit/loss and risk-adjusted returns.

## Dataset

Historical stock price datasets with 5-minute bars (open, high, low, close prices, and volume) for Bitcoin (BTC) and Apple stocks (AAPL) will be used. Data preprocessing will include normalization and feature extraction to enhance model performance.

- **Data**: [BTC_5min.txt, AAPL_5min.txt](https://drive.google.com/drive/folders/1htN-2fW1qNGrNnSYx5oeNW2NNZr4Ntle?usp=sharing)

## Deliverables

- **Code Repository**: Includes all algorithm implementations, preprocessing scripts, and evaluation frameworks.
- **Interactive Demonstrations**: Showcases each algorithm’s strategy and performance in simulated trading environments.
- **Comprehensive Analysis**: Detailed comparative analysis of algorithm performance.
- **Final Presentation**: Includes documentation, a report, and visualizations, summarizing project findings and algorithm comparisons.


## Result
Developed ML model using transformer architectures to predict DNA CRISPR Prime Editing efficiency. 
o	Applied one-hot encoding and embedding layers to efficiently capture key biological sequence features like GC content and melting points for better DNA/RNA structure representation.
o	Used Optuna for Bayesian optimization, tuning batch size, learning rate, and node counts. Despite memory limits, achieved MSE losses of 5.3 and 6.2, showing room for further improvement.
o	Led evaluation and visualization, using metrics such as sensitivity, precision, F1-score, and AUC-ROC, and developed clear visualizations to represent the model’s performance
